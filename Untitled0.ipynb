{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO0FOmyjxn7KlhjuURs3pwN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"H5O7c__4BXhI","executionInfo":{"status":"ok","timestamp":1637558667309,"user_tz":-540,"elapsed":3486,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}}},"source":["import tensorflow as tf\n","\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","from tensorflow import keras\n","\n","\n","from IPython import display\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7IqyMg6Ddrv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637558668657,"user_tz":-540,"elapsed":1363,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}},"outputId":"af559fa1-0999-46e3-9d5e-5a8b087535b8"},"source":["IMG_SHAPE = (28, 28, 1)\n","BATCH_SIZE = 512\n","\n","# Size of the noise vector\n","noise_dim = 128\n","\n","fashion_mnist = keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","print(f\"Number of examples: {len(train_images)}\")\n","print(f\"Shape of the images in the dataset: {train_images.shape[1:]}\")\n","\n","# Reshape each sample to (28, 28, 1) and normalize the pixel values in the [-1, 1] range\n","train_images = train_images.reshape(train_images.shape[0], *IMG_SHAPE).astype(\"float32\")\n","train_images = (train_images - 127.5) / 127.5"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n","Number of examples: 60000\n","Shape of the images in the dataset: (28, 28)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4vaohGEzh9h","executionInfo":{"status":"ok","timestamp":1637558676423,"user_tz":-540,"elapsed":7775,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}},"outputId":"adb7b073-7348-40f1-9d7a-4da81827050c"},"source":["def conv_block(\n","    x,\n","    filters,\n","    activation,\n","    kernel_size=(3, 3),\n","    strides=(1, 1),\n","    padding=\"same\",\n","    use_bias=True,\n","    use_bn=False,\n","    use_dropout=False,\n","    drop_value=0.5,\n","):\n","    x = layers.Conv2D(\n","        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n","    )(x)\n","    if use_bn:\n","        x = layers.BatchNormalization()(x)\n","    x = activation(x)\n","    if use_dropout:\n","        x = layers.Dropout(drop_value)(x)\n","    return x\n","\n","\n","def get_discriminator_model():\n","    img_input = layers.Input(shape=IMG_SHAPE)\n","    # Zero pad the input to make the input images size to (32, 32, 1).\n","    x = layers.ZeroPadding2D((2, 2))(img_input)\n","    x = conv_block(\n","        x,\n","        64,\n","        kernel_size=(5, 5),\n","        strides=(2, 2),\n","        use_bn=False,\n","        use_bias=True,\n","        activation=layers.LeakyReLU(0.2),\n","        use_dropout=False,\n","        drop_value=0.3,\n","    )\n","    x = conv_block(\n","        x,\n","        128,\n","        kernel_size=(5, 5),\n","        strides=(2, 2),\n","        use_bn=False,\n","        activation=layers.LeakyReLU(0.2),\n","        use_bias=True,\n","        use_dropout=True,\n","        drop_value=0.3,\n","    )\n","    x = conv_block(\n","        x,\n","        256,\n","        kernel_size=(5, 5),\n","        strides=(2, 2),\n","        use_bn=False,\n","        activation=layers.LeakyReLU(0.2),\n","        use_bias=True,\n","        use_dropout=True,\n","        drop_value=0.3,\n","    )\n","    x = conv_block(\n","        x,\n","        512,\n","        kernel_size=(5, 5),\n","        strides=(2, 2),\n","        use_bn=False,\n","        activation=layers.LeakyReLU(0.2),\n","        use_bias=True,\n","        use_dropout=False,\n","        drop_value=0.3,\n","    )\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(1)(x)\n","\n","    d_model = keras.models.Model(img_input, x, name=\"discriminator\")\n","    return d_model\n","\n","\n","d_model = get_discriminator_model()\n","d_model.summary()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"discriminator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," zero_padding2d (ZeroPadding  (None, 32, 32, 1)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d (Conv2D)             (None, 16, 16, 64)        1664      \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 8, 8, 128)         204928    \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," dropout (Dropout)           (None, 8, 8, 128)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 256)         819456    \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4, 4, 256)         0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 2, 2, 512)         3277312   \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 2, 2, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 2049      \n","                                                                 \n","=================================================================\n","Total params: 4,305,409\n","Trainable params: 4,305,409\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uihd6xMr0OHq","executionInfo":{"status":"ok","timestamp":1637558676423,"user_tz":-540,"elapsed":19,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}},"outputId":"45a6926a-59de-4801-f395-d43cae6aa3bb"},"source":["def upsample_block(\n","    x,\n","    filters,\n","    activation,\n","    kernel_size=(3, 3),\n","    strides=(1, 1),\n","    up_size=(2, 2),\n","    padding=\"same\",\n","    use_bn=False,\n","    use_bias=True,\n","    use_dropout=False,\n","    drop_value=0.3,\n","):\n","    x = layers.UpSampling2D(up_size)(x)\n","    x = layers.Conv2D(\n","        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n","    )(x)\n","\n","    if use_bn:\n","        x = layers.BatchNormalization()(x)\n","\n","    if activation:\n","        x = activation(x)\n","    if use_dropout:\n","        x = layers.Dropout(drop_value)(x)\n","    return x\n","\n","\n","def get_generator_model():\n","    noise = layers.Input(shape=(noise_dim,))\n","    x = layers.Dense(4 * 4 * 256, use_bias=False)(noise)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.LeakyReLU(0.2)(x)\n","\n","    x = layers.Reshape((4, 4, 256))(x)\n","    x = upsample_block(\n","        x,\n","        128,\n","        layers.LeakyReLU(0.2),\n","        strides=(1, 1),\n","        use_bias=False,\n","        use_bn=True,\n","        padding=\"same\",\n","        use_dropout=False,\n","    )\n","    x = upsample_block(\n","        x,\n","        64,\n","        layers.LeakyReLU(0.2),\n","        strides=(1, 1),\n","        use_bias=False,\n","        use_bn=True,\n","        padding=\"same\",\n","        use_dropout=False,\n","    )\n","    x = upsample_block(\n","        x, 1, layers.Activation(\"tanh\"), strides=(1, 1), use_bias=False, use_bn=True\n","    )\n","    # At this point, we have an output which has the same shape as the input, (32, 32, 1).\n","    # We will use a Cropping2D layer to make it (28, 28, 1).\n","    x = layers.Cropping2D((2, 2))(x)\n","\n","    g_model = keras.models.Model(noise, x, name=\"generator\")\n","    return g_model\n","\n","\n","g_model = get_generator_model()\n","g_model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 128)]             0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              524288    \n","                                                                 \n"," batch_normalization (BatchN  (None, 4096)             16384     \n"," ormalization)                                                   \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 4096)              0         \n","                                                                 \n"," reshape (Reshape)           (None, 4, 4, 256)         0         \n","                                                                 \n"," up_sampling2d (UpSampling2D  (None, 8, 8, 256)        0         \n"," )                                                               \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 8, 8, 128)         294912    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 8, 8, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," up_sampling2d_1 (UpSampling  (None, 16, 16, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 16, 16, 64)        73728     \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)        0         \n","                                                                 \n"," up_sampling2d_2 (UpSampling  (None, 32, 32, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 32, 32, 1)         576       \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 32, 32, 1)        4         \n"," hNormalization)                                                 \n","                                                                 \n"," activation (Activation)     (None, 32, 32, 1)         0         \n","                                                                 \n"," cropping2d (Cropping2D)     (None, 28, 28, 1)         0         \n","                                                                 \n","=================================================================\n","Total params: 910,660\n","Trainable params: 902,082\n","Non-trainable params: 8,578\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"qPludYoi0Q8c","executionInfo":{"status":"ok","timestamp":1637558676429,"user_tz":-540,"elapsed":23,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}}},"source":["class WGAN(keras.Model):\n","    def __init__(\n","        self,\n","        discriminator,\n","        generator,\n","        latent_dim,\n","        discriminator_extra_steps=3,\n","        gp_weight=10.0,\n","    ):\n","        super(WGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.d_steps = discriminator_extra_steps\n","        self.gp_weight = gp_weight\n","\n","    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n","        super(WGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.d_loss_fn = d_loss_fn\n","        self.g_loss_fn = g_loss_fn\n","\n","    def gradient_penalty(self, batch_size, real_images, fake_images):\n","        \"\"\" Calculates the gradient penalty.\n","\n","        This loss is calculated on an interpolated image\n","        and added to the discriminator loss.\n","        \"\"\"\n","        # Get the interpolated image\n","        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n","        diff = fake_images - real_images\n","        interpolated = real_images + alpha * diff\n","\n","        with tf.GradientTape() as gp_tape:\n","            gp_tape.watch(interpolated)\n","            # 1. Get the discriminator output for this interpolated image.\n","            pred = self.discriminator(interpolated, training=True)\n","\n","        # 2. Calculate the gradients w.r.t to this interpolated image.\n","        grads = gp_tape.gradient(pred, [interpolated])[0]\n","        # 3. Calculate the norm of the gradients.\n","        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","        gp = tf.reduce_mean((norm - 1.0) ** 2)\n","        return gp\n","\n","    def train_step(self, real_images):\n","        if isinstance(real_images, tuple):\n","            real_images = real_images[0]\n","\n","        # Get the batch size\n","        batch_size = tf.shape(real_images)[0]\n","\n","        # For each batch, we are going to perform the\n","        # following steps as laid out in the original paper:\n","        # 1. Train the generator and get the generator loss\n","        # 2. Train the discriminator and get the discriminator loss\n","        # 3. Calculate the gradient penalty\n","        # 4. Multiply this gradient penalty with a constant weight factor\n","        # 5. Add the gradient penalty to the discriminator loss\n","        # 6. Return the generator and discriminator losses as a loss dictionary\n","\n","        # Train the discriminator first. The original paper recommends training\n","        # the discriminator for `x` more steps (typically 5) as compared to\n","        # one step of the generator. Here we will train it for 3 extra steps\n","        # as compared to 5 to reduce the training time.\n","        for i in range(self.d_steps):\n","            # Get the latent vector\n","            random_latent_vectors = tf.random.normal(\n","                shape=(batch_size, self.latent_dim)\n","            )\n","            with tf.GradientTape() as tape:\n","                # Generate fake images from the latent vector\n","                fake_images = self.generator(random_latent_vectors, training=True)\n","                # Get the logits for the fake images\n","                fake_logits = self.discriminator(fake_images, training=True)\n","                # Get the logits for the real images\n","                real_logits = self.discriminator(real_images, training=True)\n","\n","                # Calculate the discriminator loss using the fake and real image logits\n","                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n","                # Calculate the gradient penalty\n","                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n","                # Add the gradient penalty to the original discriminator loss\n","                d_loss = d_cost + gp * self.gp_weight\n","\n","            # Get the gradients w.r.t the discriminator loss\n","            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","            # Update the weights of the discriminator using the discriminator optimizer\n","            self.d_optimizer.apply_gradients(\n","                zip(d_gradient, self.discriminator.trainable_variables)\n","            )\n","\n","        # Train the generator\n","        # Get the latent vector\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        with tf.GradientTape() as tape:\n","            # Generate fake images using the generator\n","            generated_images = self.generator(random_latent_vectors, training=True)\n","            # Get the discriminator logits for fake images\n","            gen_img_logits = self.discriminator(generated_images, training=True)\n","            # Calculate the generator loss\n","            g_loss = self.g_loss_fn(gen_img_logits)\n","\n","        # Get the gradients w.r.t the generator loss\n","        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n","        # Update the weights of the generator using the generator optimizer\n","        self.g_optimizer.apply_gradients(\n","            zip(gen_gradient, self.generator.trainable_variables)\n","        )\n","        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"frw2LOt40SCX","executionInfo":{"status":"ok","timestamp":1637558676430,"user_tz":-540,"elapsed":24,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}}},"source":["class GANMonitor(keras.callbacks.Callback):\n","    def __init__(self, num_img=6, latent_dim=128):\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","        generated_images = self.model.generator(random_latent_vectors)\n","        generated_images = (generated_images * 127.5) + 127.5\n","\n","        for i in range(self.num_img):\n","            img = generated_images[i].numpy()\n","            img = keras.preprocessing.image.array_to_img(img)\n","            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Z6hYrLN0TXf","executionInfo":{"status":"ok","timestamp":1637565337214,"user_tz":-540,"elapsed":6660807,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}},"outputId":"ea3f6627-a5c4-48d3-ddf9-7b9326b1efde"},"source":["# Instantiate the optimizer for both networks\n","# (learning_rate=0.0002, beta_1=0.5 are recommended)\n","generator_optimizer = keras.optimizers.Adam(\n","    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",")\n","discriminator_optimizer = keras.optimizers.Adam(\n","    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",")\n","\n","# Define the loss functions for the discriminator,\n","# which should be (fake_loss - real_loss).\n","# We will add the gradient penalty later to this loss function.\n","def discriminator_loss(real_img, fake_img):\n","    real_loss = tf.reduce_mean(real_img)\n","    fake_loss = tf.reduce_mean(fake_img)\n","    return fake_loss - real_loss\n","\n","\n","# Define the loss functions for the generator.\n","def generator_loss(fake_img):\n","    return -tf.reduce_mean(fake_img)\n","\n","\n","# Set the number of epochs for trainining.\n","epochs = 20\n","\n","# Instantiate the customer `GANMonitor` Keras callback.\n","cbk = GANMonitor(num_img=3, latent_dim=noise_dim)\n","\n","# Instantiate the WGAN model.\n","wgan = WGAN(\n","    discriminator=d_model,\n","    generator=g_model,\n","    latent_dim=noise_dim,\n","    discriminator_extra_steps=3,\n",")\n","\n","# Compile the WGAN model.\n","wgan.compile(\n","    d_optimizer=discriminator_optimizer,\n","    g_optimizer=generator_optimizer,\n","    g_loss_fn=generator_loss,\n","    d_loss_fn=discriminator_loss,\n",")\n","\n","# Start training the model.\n","wgan.fit(train_images, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","118/118 [==============================] - 374s 3s/step - d_loss: -7.9184 - g_loss: -16.1722\n","Epoch 2/20\n","118/118 [==============================] - 331s 3s/step - d_loss: -7.2857 - g_loss: -7.3087\n","Epoch 3/20\n","118/118 [==============================] - 332s 3s/step - d_loss: -6.3212 - g_loss: 0.8873\n","Epoch 4/20\n","118/118 [==============================] - 334s 3s/step - d_loss: -5.6847 - g_loss: 5.3964\n","Epoch 5/20\n","118/118 [==============================] - 334s 3s/step - d_loss: -5.3018 - g_loss: 6.9520\n","Epoch 6/20\n","118/118 [==============================] - 334s 3s/step - d_loss: -4.9274 - g_loss: 7.5701\n","Epoch 7/20\n","118/118 [==============================] - 333s 3s/step - d_loss: -4.5461 - g_loss: 7.3128\n","Epoch 8/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -4.2741 - g_loss: 9.7692\n","Epoch 9/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -4.0378 - g_loss: 7.7435\n","Epoch 10/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -3.7676 - g_loss: 9.6613\n","Epoch 11/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -3.5789 - g_loss: 9.5039\n","Epoch 12/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -3.3704 - g_loss: 9.1254\n","Epoch 13/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -3.2985 - g_loss: 8.8329\n","Epoch 14/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -3.1196 - g_loss: 9.5989\n","Epoch 15/20\n","118/118 [==============================] - 331s 3s/step - d_loss: -2.9373 - g_loss: 9.0475\n","Epoch 16/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -2.8258 - g_loss: 9.1053\n","Epoch 17/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -2.8081 - g_loss: 8.7031\n","Epoch 18/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -2.7294 - g_loss: 9.8276\n","Epoch 19/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -2.6467 - g_loss: 8.7745\n","Epoch 20/20\n","118/118 [==============================] - 330s 3s/step - d_loss: -2.5807 - g_loss: 9.6444\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9890091850>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"RCXwajZB0U0C","executionInfo":{"status":"ok","timestamp":1637565591115,"user_tz":-540,"elapsed":377,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}},"outputId":"de3fdbb4-9870-4eb4-b1d7-3b125e80171a"},"source":["from IPython.display import Image, display\n","\n","display(Image(\"generated_img_0_0.png\"),Image(\"generated_img_0_1.png\"),Image(\"generated_img_0_2.png\"),Image(\"generated_img_0_3.png\"),Image(\"generated_img_0_4.png\"),Image(\"generated_img_0_5.png\"),Image(\"generated_img_0_6.png\"))\n","display(Image(\"generated_img_0_7.png\"),Image(\"generated_img_0_10.png\"),Image(\"generated_img_0_12.png\"),Image(\"generated_img_0_14.png\"),Image(\"generated_img_0_16.png\"),Image(\"generated_img_0_18.png\"),Image(\"generated_img_0_19.png\"))"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACq0lEQVR4nAXBbW/bRBwA8Hv4++58sePWaVInTbONTdPWVgwhAXvBXvCB+HjwBXgxhARShVTKkmrqlrUpbpw48dOdz3f8fnjm6b1QBWvJ2Ogao6G2SlaojwbiEcgOWClYoOjra+YqVDntWs9Tck1zAtZRjBGmNq+cR4mVArVtZ02tEDhJnMZYlEz3LlbLQogNgtJqYzsHktXhoyWPdX1bSa18+dzUgy3Op/umhZIobDrkrCtp+4I2T96Ja1ZyH1nEoRK2tg4jh70ACl112gLjAkPdeeAw15Q6w7TZ69hOvHf9OL8J7Omq09APLNhAbRgZ9dlpezHyvH221aRoGCWhrHK/VaRxvYRVaPxD3o5bU3Z2IAkwID5uHK+8787vv/r06gxvtk+uwq+PB+4fyKPIFrrk/BBPTXR+Puzezk5T+TOZj3+F+IxmhVtY5Rc2WtOibevA4fAQml4JIzYOC02298cDERZqFpl2LeKoXT4caRBC2mpofTt9msg7ygkBj397MMHdSR9WJ/NoNgkWgo5PcWBSf/X3MntIbn479sfQD9JDIY6a/6xUUlSjYCa+r3KarHvTM7iT6vfR2+tPxc3lrMzTbzy663iGiOZmBZu82dIsu3IYBWWe6uf4yo9/Ecni2e4jxAcPPX/wtOndvflxs6Bdx0MIR7vOAn0N91Wq/aPHh0nhCRvf/tuoP+rZ+yLYf0wuYYiaTr4ICo5CuZsv1ztxncEmD8wOWaBC6F6MG9IbhZPsS17rtrjNy6xEVpMT72DCWcD/TD9/qOaf85RILwOrPU0t7LUP5jJFa/U+JvM0P2iNI+C2Heo6WB+jn9AFIuEX/yhFEvlLVQkeck2GBuBZO+2/AbL/wA79BDvMCTYOUw+EwskU2yIh0WJvXoZ/oWqIC8WTDat9G/0PjDF1QUt8tpgAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACtElEQVR4nAXB2W4bVRgA4LP855xZPJ54S5QmMU0XUCmtoClSFQkVJC54DV6FS96E66qIS9SLcoEqkKoQltpNFZMOtmN7Zo5nOSvfh8daDap4G7VRZaAhqlPARhAcbzkVeBchX6eNI85r7TClwHVkcNDWrAveW6dKxzCmFCEgjDDADknktYRI10HYtVRJqiCkx1rka2dszZBg0CLbwNq32hMndJuvw8JhjCjjexyPOt7o0jvviBIPq2NpQ+X/ConteA/YWkEMUooLEt/aHur1oJF7o9QG+QUUYNGOF41kWDbAyL1NN+fhEZjo3RuITe2RQq2JGSf9TpLMVun81Wu/W+dzSNZGJO5wND2hUfMVU9Uk9OdzsNEXLwxY8Bw22Txb0C6cDG8vvu3t5s8EftLrvgcaICpDKlKEH48fp81u3t8pT/3dvYQ8B+9JHApB9Li+PSgZEZFwaK+dX+1/9wosEvtffuCm7542p8Uy6rmGlHacZdh+8hOENWxXTOW8l/MIAuq0Uy1VngejkDQc688FGumg04+4XchMzn4uX/53ffaWQZnsfHwnvTwexu2yNs3Fh/cGRw/6B8w07EcQ44864fKXFyyacBnyB/scCMKAzTWOgDhxIzkdKvjs/i2/ilv7Xpy/fPpseSbNFLrHT2DoeUeOeokNeVEp7O+PT95UzVsFfDEpHulVIkeStBENXIW6Mdz89Gv15/dQXZ3xHw7au315rYcKZXbL23xVJf/SiYaynsGw73PDLodhFcz8Gte4s+X04nwJtGge/fMNn86ufv3j4eujK+JJimKWZg3m4IUozTX/bX6n3P59WSyMcqFr0SJJJw6i5WYcZ+HZ9Pcab6QqHXYFs+gyTtYjuGlSj2aQ5cghqKn1AtPA0cP2sDjAgxwx66ixQgMx3hHKaadlcY7ljf8BRwN33njPFikAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAC5ElEQVR4nAXBTU/bZhwA8Ofl7+exk9h5dyAhCckC6UAIRotWadq0N009Vdpl532G3ap9in2DXXfqteqh9NCqaK2o2LpuMNYGCMQkjXFsx/Hr4/1+WAGaI1KIQ98nm+Y4RnhZsiOPZ2UWAuORnUgo9SKk+I7Pss2twdJlkFgkQwGlhAYSWqScbH+aO/o2P2292n3/5DDGOALAVDUJRF8yuZ5+vrvxm/vu9v3TVf3EDkMIgQAOCOtaVBWi6Ck/EJMq0ifRgYsAM8Kppih+YCjefjVzq6Le2MOF9C47oxAnwkEMZOn9aOAiEMWfv+G01UDj0dM58DBhoSSHh2O5Zs40vrMR//LAmNzsKy4HRgQmEckd2zSyJd7sm/Y/PIreXnAHgKZqnOGouOmYE6VSqxmP1J2MHleqbR+I4HQRx7i9SmKlqhcI6vUXV08ep/D3xASCCM5Qrf/rqd8s9ytivdE+uTBGW35AAZArErncQc6SDXhoAMxVtVW0dh4NZghEgLHcWVdWWudeQZ8W59O41zSr4tYUMZAXDJeIXbNKSYprWT2Ty3mRZUtv5rRMLCLFYl2XPsOBWl1rZoO11S+0xvbeTx3ZBy2R4ulxxcl8P/br60P//D/FiueaIntcAZRO0HK9bP+Z7RFxPabFtvmSirCSjOJLKKPpxz9+lTwMjJo9X3X0bm+hNY4ZVW+bL2GgeEw4wXFmpfN8RnjpjaOxazHMo2bjFSBCSuwvDz7abH592Yk1ouUybsO4KmY1GeqVxd32eVeZaql7uMiOqhaj3vKwRdSxCdPE+0OQDRCJ76oTK/XCQnnEcrggB4TEQmskJ4i/jqL+vW53SU8+vHg42T8bvp7roK917+q73fQ7juy8hng5X3BcWf0QeGMDxL95D0o86ctHJvaii2Blu3anuJmiSu4SDHtw0Lt40DXv+Hk1tM7cF2f1JHeqP/tducJNg6hVY691fe8gse0bb5nM3K29I++txdj/mrdgfBifLtgAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACpUlEQVR4nAXB226UVRQA4LXXWvs/znSm/wydMqVMWqhWgo3GSuDahBsfwCfwgXwAL3wIuTCmNyTacEoIiRpQWsGBzkDn+J//vffy+1RSoHGRKduj+3cuPh4dffj5dDLNrOO4KcCLwigImW6fZGU2Tl09e/BFEGitW50e+gChBmx/95W3LK3Y1O5/3ydWGrFBRxSAhc/2GUz7Wlx7wfa3O1UpQIAMzlUStzcNoq+auo6zpbZh7aQhQE0svvD7t6LCytYhz+vu3TBQgA7YgIC1YT8RoMY6Ui5bFygOCACNiCnL/OouSGU9Cw57coUUKRFEBLGNeKNrPiq2l0X5sSlbbe0UgqBSZMUNNl+5Wub5498vz/rU7guimBJZRJC3Js9Et0La2O19go/Ok4CASTOKM7J1fJJmLfXPg4c/oKfSvUPzW+ozskVloy5n45mvoTtSOIi/nM8af2UsMxcK9b076zfbZAjis+7MfxWtrpB4jWNERUE1PZmv0KUteDeaD+eLspt8cE6hUQJXD3amSwMb1yna3x6pvuDugc+ouCGK9r4eJL00wMnzJ8kOwKO/W7cOf6mEmEibxfvBW5h+Glz/Jr01xKzTLm7WnjEaG1PnC7PKqBNaG5ZndVPcdGvc9EjVqJwnwUHBdwf6cvXf6/GztOJiLjpQSlgUkjw5z9s2h/69x0dJ7AdNOYyjFRIiVjz+8001/lf5naT3+V6Er8/LykfrkEUpdP3IO97bIPaSmFTTgexiwwg4JgMtGU9zrOt1O7qxJrkYj/OHy4UDxWAp1y/ncBreqO4XPw6Pbz99qfjd2ujGsWehDnIXTH4aHbYmpzT+46/zVF5gyQrZEkud1d4qq2VrUXizF8vSr0FQQ8AQNsql1uW5zX8dxs3sQgrPzmLSVfk/jOlr7Gl78r8AAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACnElEQVR4nAXBy2+UVRQA8HPOPfd+M/NpZyi21TB90PJWecTEGBUC5bkksDRxIQkJfwn/AGHHgg1bQoILYyLRBaSEBBMsiApVW4c2paGveXz33nOOvx/uGCCAMlcOXBUoUmIrewEwmeOIQo7QApiqSmICR6YoJIGDGCiAiTO0bApiWomxMiUurOg6RyoGqoYmztz74rArUGKTLJEiG+ecCCIBsK8oRFTHpAiGlg1AJSFAgUYesSaVI1YDIyADQyT0IWWznKoEFhnVDxCAUC2JcWtXXGOJyuacUQbxzKySzBDC9XsPbk1GRJEIJZcxIoCBM1RO5anFuSfL1ubucC13uWIhAwcArnGgcWWs01kAXFSrjjXncUR6PjpGq4DvVF+Vzw7O4U+Lv++f3fvBVfZZDRFEQp2nHveLNxNLn18LCxN1bV3kvkex6A1w/FD9dAMbt2+Ob4IdO3J4dpHHV03BVF158uRH23mr8Z0c/2Vm6hBDvcblOnK9n2tjU6vpj++Pbuz0l/23Y6nxdmdmXqp0wGDTZ9txrTcy83h5LXxYy47fc9V9PvHNk58nZtIZevrSfbYNrzePb8vz9cHEKxdWuP5ivtMcq23myZX094vxPfXOy85vX+8q203fxgMY3w6PdDe/vPTJf8/si8Odu/f2jJxzvenp/gVufUrPjbD18V9DcXS0tXzjwcKf9JrDpXJugWc3tlqxnm1+8ofR9pt/5x7q5HqrceLUUOmH+Ecj6jej8tN/YiF5rcsh9fPyo33nX+3GZgIUpoLDIIch6K4SSs0Pp6nG7l9ZmYA89zMpdLMaOUQZ9Gij0HdkOTuTfgbHAKlSBrRgGFxYWmIGRDIliIZoWmnhDdE0ba1UOMwqKABmkcSBYi6EzPuoZv8D2WZv3qQznJMAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACdElEQVR4nAXBy1ITURAA0O6+fWcmM0mMIQVBQClfVAkuXAiWrt34Af6Aa7/LD9GFuqC0VEQKy/LBQxJJeCSZmXu723OwW7NqUGx0i+XTy6s4eLH+8tBx1ag1ZdGaasUrm49Wc03//Pv27M768cRzSKaR0ZuSkI2+yk1ZuVjanLNRACcKiFwSgzRk/CNfKbf/zp42B3XZHhuYqjIBGEqFc8+3rHXkW2F40EkcGjoyRgnGSu0uHvSW8+rL3GLavFQEE2IW4gCInO5/7N8q4vFJh++9KwkNVCk1NYlWjlc79zeyi7T+hBqAXEaKjADEyhi64+udSasTP5zuCJpFD8hqQJn3g2lv6GdvFrq2uH8oaQxozhjIYinRGivfNT3LX4M8fHQ81QyUjBQ9Qqyh5bfJbz7u333y2J2WdQwizC6aQ/MyOfpzoNdot7HBP6sEyUCBDVmFQjXYXcuGVX+r16jNN0sSAyOSYIiGUKy3J7OLWAxHRyYqguQogpiZWvV2mdP1Xjbql4stcMTOVUTsCR0mtDvc/gynv0+OD2/kQcUAjYAMwNA10v6Dtdvty7iXNwsldhiRIzlABNW9X3MNmq0ud+YdAAREQWIiRwQpuxstqt7/mE0P/0LFoGrCoAagGhRm5mNcaFdT19aKDH0gMzNI2MXrU8nO6tnOSW9SqxInDGSACAaM8bxZpGumSz0HIKYhKIEpsoboio/WAre31yz2EwfOVFISgRiQBOaFbTxJ2gVeTLImEyMygFnMPPeX2hhOukuL6cF5rXUC0YQJScM55KNbm92rC+5a/vPVwJNNnUPEHEiCr13tiX3VGzXLiSVJVZRpsP+5KmtcpXAs2AAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACYElEQVR4nAXBy4oVVxQG4H+tvXedOvc+5TmKrZhWA6IiBgKGIARCIINARo7yAHmUDPIamWSWF8gkkFlwEIJEUBQFW8VLX9Jdfapq77X+fJ+sBwJjm58eXntw3zeP//jxt19KqUowsdg7ILo92b3263zQnS++Ob4ROxdnKqLuRCCH5lz8+NfT/YM/F582aoVWXFUhGqDQH9azuLH2qzTn4B0FAjUHrC/T7+9HnL182OmLV9+ej4EOIHpQH/W88LXb4k7TlqPrlx6lIpXTVZWku27zwf6bp6XLBx9wY1dIgh6FliZZVtv15cO9rl6HV/XnN/9xNRFRgkPXh/r3F1058PZ4/PpJm7Zbd6erkqk4bl3dz7zYDM9k73mzgwBQTB0SQH5ydw/b3o/qgZ9deBBCCkEkwgMyzvpL9Xj6bsb8LzelHlCJMWglLA5py1GZX1xfmUQcv/kbzA4gFiVE4hVf5FF11l9ujkp1OzjhZHTACNeUHMVyK7NivUAoogoREeiXC8uH71LiqdaYCSolXWlm7lRoNwQfrHXEZcBAUURChCgneaNCXTaLk8oWVa9OMAZ3EQnL/nRiJSQvhiGJGwlRKMV9dD6bYtr15b193OeuIEAYi1LJrGxGT5aprpdRU9qBiwoiJCaBhpTiuWrEHC3OuIYQhKpDASdDGHthEoxG2NIVoCYpQ4b8dwoHPMfGQ1XdU3VAYwlIJquVxbQyFmBaERsdmQMxugyONTqbn6SQ2+lsmMgxOqhWEYUCbLvJQiWgnoIx4t7CizDLxERTu/rup2rcxpn3H87eLh///CzZmPgfinFgaAxWl50AAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACf0lEQVR4nCXSvW5cVRQF4LX2OXfuzLXHk3H4kROP4gjJifgZJUgYikRCFCgpaEF0PAAlDUV4AaipaBFSBEKBAgrkIkAKpAiwIgqMFHAMtjOx48w49vjec/aiyBN8zcdWbIrALHkwV1AGvfAUjJ6jGMzhiBkuKgEwZ6BUWAQLa0AlF0E5SQCMcjjbrSbDBEBBTgh0M5ASjQwsigCLRgGEYIFmitEj4MGywCQ5ZB5biVQuj3OIcqgm4KZoWZISnIRIZ5sh5VJIsRaTnmBFUbs6ObZCKoIlILtIzHaa2lOSK3YfRNS5Za0iNRmxXZ27dnr/+t/bmy07SlduxGqSFA+Te/FUb/GjlzvN5ul3dz95yOX2O9fjOIApM/RXrn46HP0xuXW8evX7Jttw6Qyi+nW2UD679NbcB5cPNm50X7hy8Oi9ubuXDnozcXZ+vx4Mnl/ZWllrvul9N3jtK7u7137z8MvOgsV8sdr9cGH62/3Pb/47aY8X/xo9w931V7eORr+P2Vv7dffC9o9Pv/7Lxk8PLw5nv64ur97bqWaW29UXkbe/3b41/rP8Z7t7dnBuyOErZ7fef2682Vtd2KC9+PjkG3e2fLneu3fi/GT9uHuhWX8w7c/O5dssPx6v9avFuenO5ORw/eb989Pez2mGC49z84gzJ+b3q1P9/8YvXXobo83BqaN6Z7E07k/vfEYw9gsPTXfpzA8TNQzH6rSnYX5U7YkBIQtgkV16MiTkQCAcltEQKaAAE0RQLCV3ESw5n2CxDrWY4ZAAwiSHeYwN5HAXJQMF0ORgYMyMMClBygRMpJBphFmSWIEKGZBEAe4GkECAZ8uNKMkCmLJkBKAABSj+D5J0WeL39BxyAAAAAElFTkSuQmCC\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACkUlEQVR4nAXBXWsUVxgA4PfjnNmZ2c2YNJs15svYUoJU0VbBFlS891LwXgT/SC/6N/wL3gteiAgFAyEKMRHbNHG3m+xndj52Zs55X58HAwAFi96y3N/4NauOD+++6qXARoAwVEFrc+i8DF6fDIf3H799kT7Z9yGqI1Ii0rmjPx7cezjm7cfrRwfVX21wQChGBUAcbDzrK96xxSf/ZFHSsXhGVFIFQE9/3m3y4LdN7e/ZaG21AQiixgCiBBg+SjJZgdWbQeMs4ssbFyDGgzEKGBTrJhuOYm6C0zLFYhkRAYgA1VT2adBoXOusxUECnay5+rxBVkAJVOuS17PDvWJ0Hpjm1XbEi48WoRKtSYBVk+uurHhzKVSXSX839TGqWiRQQNz+udH2Ax9r79uAttLdSRIF4ohEAeEXPA23wI1r11nJqc5Xfq9Ki0TGGsWls38ZKCxzV/ly/veH4KaKIhK7inyr0NYYKZ54qcK4SdXOAqAKVQqgn/9bCDYkrV1QwULzRjksgBiUgEhtq9um1tl8lvGsKIEOj70AEBOSwegWLduEwZSo81raF4dFRF4dkbHCSWdJaKGiwPZsTteS/S8BoSKhq8S3slpNOB1PIfJHo3hx+LViJiEg8HUysTCZJZcL/ua2RHrne6U6ZhIvCPlJQclyaXdWr8RB2bg9rSNU9ISiqt3dTF1Pa1PPMuH58SC7qH1tSUQB5oOTctTn85MRJ+Wk2J+NciXwRCCQTMfvx6Pu7DxLAU//mc59LqIKpGwwzNI+Zy7K6oA/tm7obWaDCEgiat2evJlu/dhKuHPr0s6lepMFLBAYIObZu7x3uhbG213XPZj3Xn3whksVxUgRsPTYNK7hfvjp/0GdORBDHg1/B0hIdNEIH6+kAAAAAElFTkSuQmCC\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACnUlEQVR4nAXBT29UZRQH4N8577l37vzplGFsmYIViYgEhejG4EI37vUjuNRv4fdgY+KKBYlxQXcSDUaSQlAyRECaThk6lk6nM7dz69y5977vOT4P1QKc0toifuuru68yF/c2tiNqpx7BETUCuEq+/+zcZnZ0uTAfJY4eb/0Q8kyFmoaK3r417dLD61d9sZEdd+LQ+/Pbg6Vn9iFY89aNs7v6xfvPX6TpSnrUbyz2umleVgIJhq3feqsTWz2qN7c+6LQ4ml/4rj8FBMESt3+52bLpcDkcttcnEm9fjG9XTiFKzFQ1VlyUzro79XY+WJ4/oPt/lAQSqGn8IP5ysDGvpxc4qp+70pQ4bVYZOSEiK93p9NqyiE/a0j5ws6dpJ40ETAzzKOb3f8H+1/VJNRo9S3YnF3ffvE4NQQwcFc4X1Vke36Ry+dHKqH3vcdbJSjJhZ4KC73768T/+RjrYq3XXnv2Y6ylYnZhHpY5m7V6S62H8zfDR8Wi+rIwieDEBiMKivtef/9v4cHWSjHdquTOAldlMIYzE9z5ZfZkfD/VVDHIRszgxUzFWa5f25Hi5bJ2Z9DdUHQBAiC0QgfLF3/XZzqa8G29efz03AL4SNuZQxH79pHXp2p12r7n79HQemauASKAwBarT8eDlWlnHr9uZEnsPZWEPZ04Ql2fWbybPRyvvdGqLmBwTtGTHRGaej3YOo/LkyeK/FBNAiB07UQSnEVu3cz6fjWTaf+OdqpmCTEgU7EJymF2VVm0xb7U4IgUZKAgqVi29//mv9z7/fWE/DcbIDQQQSIJZFATuBPu3XxQuSyupnDOvxERxiNREk9oSkpfcCOqCkqoxk4DMpBG6qWt1xnOHRgEnKAutRUQ1YViSe0JceYKRGbOCmNj+BwPwbuOxLfwCAAAAAElFTkSuQmCC\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACiklEQVR4nAXBPW9bZRgG4Pt+3vec4xPnw7Fpjd04Iq3cDhEJlIgurIAECwN/ACRGVAb+AH8CMaeMSCAGxNCBiSJRJIgEIkVpaV36ETu2Uyf2+XjP83BdjI1KpWiFpRsPxhv2dGFqVMCchwFwSiC++V5y982zT5+MIaIARQQizkzB9ke3i75tdj3ElCAV3sU+ir2D2z/57K0b30zu9CC+FonzzrtgAoBovoPu53tS5b1xrgUpUFFPwMy5FT3Y27Avf7v67nWQQlURUzOlhLjz/MHZ4zG/PomGIAiAXmgAoLrdm387/OSD0fe3gphWRqhAVQmjra7vvLbefrTZHqYUACCEjg5a0Y9lVkRudL8/i8wISmwCGEBB0bZ/No/v7UnrQlZCFCGjUGGmIrWNRbP7xa5rPrwZrAqkQ+IBApak9TfyJRk9ifuL3pStPJRBTWBKgaTVBLXTv1evy59HgU1dVBT1ACDINX95rfo3uxY18v0gK6WSpJcKaogutYbZrH0hPVzs9i/90oxKVzGIUlAx3vr4cnbUEGv8Pu3sRN771HkTmAckSrc8Ntc7kWzN3V/1y3WXIXhvMJU4u989XH5pEFqD41DuFLVcAqkSYKhajebS9Eq9czv0jnfunm5dccHMQyiAaX6sWjziea3xEN3dcpKbMKL3BmPnReLmfH6+PDovlxuD6R1EmQp8RTM0XrkWPdZXOSzXerXtDLw4HwUNHmae2elTXp0moUjq/fTiD9NsXFaAF6Gw9vqH+C8+nJ9899Ns9setA6YpUBm8KZlsv1072r4npz9Xjf3iLHaT8xAbxItFa8kLHfz4/uTXbOXgq2fzs+JZpmLiyQTQaHVpEJya0QgTxgEETP4H/mBFPlccYXsAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACwElEQVR4nAXBS28bVRQA4HPOvTOeV2J7Ysd523k0kKaEgohoJViggFBVCkiskNgUiWX3/RH9F12wAwmxYYWKWiGggoiHAm2KFCduUuzEie2xPTP3nsP3oSeWAARJgoFXfve7wfWH/jBFJkFHWxKLIBqt8aMPt/caN54mLIIWyGBAGYigCGDwdnfh8/0v/7v6cye3ymFLbFAYgBH4CpjzLGp299cAlGTMGtAKImhhNTtZb35z5/5Xm/4Iks65WA2AIAJAlvuV7OZwfl1fdrd2937AvKcBAVCAmfHh6czh7u3C4e/Lbuev31LtEwOAqILWCM6CN3fwI9ci79nuSyvEOSEAgjUCSPjvwI9/abZK5fhF44uCGNIWlQALUMGkU5u3vbRmnHB15wOHmZjZKiUo1jRgo/I9N+Z+ytX7VUjBIUFrhIVz4SAcit422WYnyS4GVRAC5QcKCRXyc30l/rR0XnoFCE54A5mMNUSaAMhbftXvTxeTk1axvp6k7zmsCSBjR1iB2twqObb9pHp5dDSOp96pHZInqMApkOOufLxSk+HxrGsxzlQRXkdiYMHZhuuv3Jpb/fsBlpb0QSt4LRzRZ5oAQReywVRt+yY9ouHuclSNi54z2EvnRSOC3+uX1nfK8/2lxf6w152YZmg+icsJa8tUWtiquvhGZKv/TISylLdhLbnGYQg6N3pYXtqh3lzqlJMZnsyPCr4zis8kQiKAl+/emui57VPgKLR/XHhHRD1dz18QKXdyI1H1qxFPhmN75tb7nQeBrmaJbTtkorX1x6N25nWft/KjZ14l02XEGdMMxp72L935pNM9dnWaHks9bu6Prn1UUf7qImZjPTpxzv68vjx2skwFhoJCWB5YuMDHvz4y6Mn0m917Dcx9SGHv4NuDxcrTt06/dluiEyzmZDJvVhSnPWMtAwA6YonAHf4P7Nlasn/Kg54AAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACgElEQVR4nAXBTWtcZRQH8P//POe5904mb53GEHVEa9VSWsFFEBcqoSJuKkUEF4ILBTfuXPoBxG8gfoWuVERFfKEgipBIbayWRtuKCjUNpjGTzGTufc45/n7MUiQCQX/Vcf/qxvVn33GQDqRg1lbpIZ6+60Zn6vW/Xl771YNJTEIEFIMGep/cGax/eEo2X+9RK4MYxEuUCHfPe1pm/5k/ftMn8MgqKUuumOuqytKcf2CbK+PdU7d1sddH13lIF2HmXYnOR791aWbhcPj0U3XXuqaiBMIpucPV5Zi//O326erdo2mImGQhhAlKVJ/OzZ041vQ/fmgy9gBpnYTBI8xj/Oexu+Of9tI3aiFa95SU5KSRBQXD1a30XFz7uqTZpZg6k7g4sprSXug2Hnvj80cvvOdpf7ttC4o4AbPwiEf20+7hpdH5Fh09EBbqIMOBSFd65wY/PF9/IFUByOTQRASdZOysPD69Olqrj1onKpTIAvcIssjyM1dubeHta5f2REQ6J0wckiAI37lw+/3N3szqOVYLg4XZqm6UmWAISsiP3z/8b3tmv/eijgCDMdQ1AiXEcfOLJ5fqi8N2t2k9QBAiIXBRJFwcvnZwfW3z9L3wXOe5JiUlocxJDlZeWVjEEydfOrmCcQdmy6Yh4mFBu/Plm79v7I33b/3SJpKlUxOHuxOlmX61/VnML9+4TCphTgtFDrikPibNCT3Lxbc+Cpk5ciajqbQOEJb5Rz1cn/brn90O6e7QpAgyGO6Y3uDcYGlxEGwmpJi75mqmO2os5nZ4Vu7Gf9XAUSghblRvJxEt+5PZ+4638/53UxypBR2JVCKF08MwOLiHuw9uWeqZRQpL/wN7YmDMSmLkTgAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACaElEQVR4nAXBXW8UZRgG4Pt+3ndmZ2aXLqXQ3UpbKYhU0QJBYzQeGT3S/+CBP84zDyGBEOJHjCRKLNiExiJpoIQuLS1tt7vdmfe5vS4WchODlq882D1OVKy69d5EWZKRLXp0eOt2Tw/mXw1bd/Lv37u6DzOB0U2NHGn/9auDmUfjbm/2r+4EAEG3jCHSGJc/Olz69+JKsXA8110GI0hY7XR6Ghc7GwurzoP68uzuSCIAmCFRJnVXPl/9Ye/yd9VkMHsMJAgwkZQQ/nw62JvvL05fO3PXr2dmhJkpmVPs7PzzznZ5vv34x/Q7nyeRcJlBbuTw5/yT/sHp8qv+YbuzRDUiPHoAMsl/q0P/6UFnfOPSk5/GQUVDSwaBCVT88IIPNl6EJ2vv/7oRmOQ1THK5WXp5yveXV29dXOzO339pIMAQDTIppKOV6dBf38+X0u6bk3YjOoM5oJiS5T3Orb92prdjyE2iUoRDyZRm62fntzz5Tjg38REASEYTnVCUkErk03YOMCNpMAGShI+L9cHRcHP89ggJYAAcRtIoWK/slDH3Jm42hDeN3GUEXBBmhK1RPnfSFHUpGEGjCUYA4VqoWtvDanNU/z1Fy5REmSSYwbrH4+0/NLNpRfo6pIZG0UykhKYI77Ip+6HqPWrlniQimCiAjM2zcioO/9sqFwZIEGlIJhnhKHzS1umT7LA5Wx3VctJEgxwA+GZm8dOb2Rdf+tTVG1MGVxJMoDtQbv/ik7XJ47X1SfVwZECLJEKIWZ5l7c+uv7h3ybIPvr3fr6p2yGK0DHkMZavIeabzTZdAiGcZTxWhCFmw/wHqWkXAFlZUnAAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"-z6cK5BIkwyB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":45},"id":"c1FJeqzc0VFc","executionInfo":{"status":"ok","timestamp":1637565932434,"user_tz":-540,"elapsed":540,"user":{"displayName":"고성주","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06951970941607314716"}},"outputId":"a3ea2be5-f3e6-4fb0-9746-0c8d9b99d77e"},"source":["            \n","            train_images\n","            img = train_images[6]\n","            img = keras.preprocessing.image.array_to_img(img)\n","            img.save(\"testimag.png\")\n","\n","display(Image(\"testimag.png\"))"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABNUlEQVR4nOWRu0oDURiE5z+Xzdl1ky1kCcRCI0EFK21EsLJIYSEoIl5eQEK0sswT2Fv5AL6FjY2CTRDsRAwJglnJmmRPzN5ikS5gZSP4lTN8MDDAP4QBHAABgJgsOQCg0vpJPrx4eapfA5C1Cbu0v15+bnbntgAcrI0zggQA59Jr3N/ePVzVz+GeRvOrIAAsBbC5d/TRinPWQNvv7szgcVvZbRrLZyf5Zi/OI0XYHWYzrzuoVRrHhJXyoirYYeCQ4lpSOAxHtEB2s23diOquSaHUZKeBL1JFGW4q2U06sZkF5ZY2lmenTZEw5qbcEAz9IIxHX6wzVSUn0jCKpWJBEUu9vud/+lrDIHgBCFaOEGsVgY+Y4oZUyszKSFi9qDFeqyS3MhKcJWAy6pGQCU+Ct18d9bf4Buq5ZchkOCnbAAAAAElFTkSuQmCC\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]}]}